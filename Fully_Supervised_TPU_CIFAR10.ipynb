{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scratchpad",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayakpaul/Supervised-Constrastive-Learning-in-TensorFlow-2/blob/master/Fully_Supervised_TPU_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lIYdn1woOS1n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee70c389-9b1f-420f-9941-a2be07d16658"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA9qurlZMYgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate yourself to use the TPUs\n",
        "import os\n",
        "\n",
        "IS_COLAB_BACKEND = 'COLAB_GPU' in os.environ  # this is always set on Colab, the value is 0 or 1 depending on GPU presence\n",
        "if IS_COLAB_BACKEND:\n",
        "  from google.colab import auth\n",
        "  # Authenticates the Colab machine and also the TPU using your\n",
        "  # credentials so that they can access your private GCS buckets.\n",
        "  auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l43puTskMnAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detect hardware\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "except ValueError:\n",
        "  tpu = None\n",
        "  gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "    \n",
        "# Select appropriate distribution strategy\n",
        "if tpu:\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.experimental.TPUStrategy(tpu) # Going back and forth between TPU and host is expensive. Better to run 128 batches on the TPU before reporting back.\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])  \n",
        "elif len(gpus) > 1:\n",
        "  strategy = tf.distribute.MirroredStrategy([gpu.name for gpu in gpus])\n",
        "  print('Running on multiple GPUs ', [gpu.name for gpu in gpus])\n",
        "elif len(gpus) == 1:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on single GPU ', gpus[0].name)\n",
        "else:\n",
        "  strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  print('Running on CPU')\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiETcYIBCbQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fC3dY69DDDvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/keras-idiomatic-programmer/master/zoo/resnet/resnet_cifar10.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlE8sCiICubh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from wandb.keras import WandbCallback\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "import resnet_cifar10\n",
        "import time\n",
        "\n",
        "tf.random.set_seed(666)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VRxBXldDOON",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_training_model(optimizer=\"sgd\"):\n",
        "    # ResNet20\n",
        "    n = 2\n",
        "    depth =  n * 9 + 2\n",
        "    n_blocks = ((depth - 2) // 9) - 1\n",
        "\n",
        "    # The input tensor\n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "    # The Stem Convolution Group\n",
        "    x = resnet_cifar10.stem(inputs)\n",
        "\n",
        "    # The learner\n",
        "    x = resnet_cifar10.learner(x, n_blocks)\n",
        "\n",
        "    # The Classifier for 10 classes\n",
        "    outputs = resnet_cifar10.classifier(x, 10)\n",
        "\n",
        "    # Instantiate the Model\n",
        "    model = Model(inputs, outputs)\n",
        "\n",
        "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zgCVrD6DiSs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65505a65-573c-46b0-f40e-74524279aac3"
      },
      "source": [
        "# Load the training set of CIFAR10\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJ6P3sYpDkSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 128 * strategy.num_replicas_in_sync\n",
        "\n",
        "def normalize(image, label):\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    label = tf.cast(label, tf.int32)\n",
        "    return image, label\n",
        "\n",
        "def augment(image,label):\n",
        "    image = tf.image.resize_with_crop_or_pad(image, 40, 40) # Add 8 pixels of padding\n",
        "    image = tf.image.random_crop(image, size=[32, 32, 3]) # Random crop back to 32x32\n",
        "    image = tf.image.random_brightness(image, max_delta=0.5) # Random brightness\n",
        "    image = tf.clip_by_value(image, 0., 1.)\n",
        "\n",
        "    return image, label\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .shuffle(1024)\n",
        "    .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_ds = (\n",
        "    test_ds\n",
        "    .map(normalize, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7dJfnDyDr2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "536d0ff2-c03a-47e6-977f-b8d1a5ecbab6"
      },
      "source": [
        "# Train model with Adam and EarlyStopping\n",
        "wandb.init(project=\"scl\", entity=\"authors\")\n",
        "\n",
        "with strategy.scope():\n",
        "    model = get_training_model(\"adam\")\n",
        "    \n",
        "start = time.time()\n",
        "h = model.fit(train_ds,\n",
        "         validation_data=test_ds,\n",
        "         epochs=75,\n",
        "         callbacks=[WandbCallback()])\n",
        "end = time.time()\n",
        "wandb.log({\"training_time\": end - start})\n",
        "print(\"Network takes {:.3f} seconds to train\".format(end - start))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/authors/scl\" target=\"_blank\">https://app.wandb.ai/authors/scl</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/authors/scl/runs/3p1ax0vp\" target=\"_blank\">https://app.wandb.ai/authors/scl/runs/3p1ax0vp</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "49/49 [==============================] - 12s 252ms/step - loss: 1.8760 - accuracy: 0.3047 - val_loss: 2.6551 - val_accuracy: 0.2058\n",
            "Epoch 2/75\n",
            "49/49 [==============================] - 3s 55ms/step - loss: 1.5901 - accuracy: 0.4158 - val_loss: 4.2850 - val_accuracy: 0.1441\n",
            "Epoch 3/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 1.4547 - accuracy: 0.4702 - val_loss: 5.0781 - val_accuracy: 0.1450\n",
            "Epoch 4/75\n",
            "49/49 [==============================] - 3s 55ms/step - loss: 1.3453 - accuracy: 0.5136 - val_loss: 3.2046 - val_accuracy: 0.2270\n",
            "Epoch 5/75\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 1.2486 - accuracy: 0.5516 - val_loss: 2.5544 - val_accuracy: 0.2766\n",
            "Epoch 6/75\n",
            "49/49 [==============================] - 4s 78ms/step - loss: 1.1715 - accuracy: 0.5821 - val_loss: 1.8376 - val_accuracy: 0.3873\n",
            "Epoch 7/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 1.1126 - accuracy: 0.6027 - val_loss: 1.8737 - val_accuracy: 0.3931\n",
            "Epoch 8/75\n",
            "49/49 [==============================] - 4s 86ms/step - loss: 1.0433 - accuracy: 0.6294 - val_loss: 1.4002 - val_accuracy: 0.5013\n",
            "Epoch 9/75\n",
            "49/49 [==============================] - 4s 79ms/step - loss: 0.9972 - accuracy: 0.6460 - val_loss: 1.2843 - val_accuracy: 0.5541\n",
            "Epoch 10/75\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.9564 - accuracy: 0.6617 - val_loss: 1.2569 - val_accuracy: 0.5524\n",
            "Epoch 11/75\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.9087 - accuracy: 0.6805 - val_loss: 1.0342 - val_accuracy: 0.6340\n",
            "Epoch 12/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.8651 - accuracy: 0.6953 - val_loss: 1.0728 - val_accuracy: 0.6385\n",
            "Epoch 13/75\n",
            "49/49 [==============================] - 4s 77ms/step - loss: 0.8315 - accuracy: 0.7077 - val_loss: 0.9524 - val_accuracy: 0.6673\n",
            "Epoch 14/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.7991 - accuracy: 0.7218 - val_loss: 0.9645 - val_accuracy: 0.6709\n",
            "Epoch 15/75\n",
            "49/49 [==============================] - 4s 79ms/step - loss: 0.7640 - accuracy: 0.7322 - val_loss: 0.9424 - val_accuracy: 0.6706\n",
            "Epoch 16/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.7369 - accuracy: 0.7415 - val_loss: 1.0687 - val_accuracy: 0.6539\n",
            "Epoch 17/75\n",
            "49/49 [==============================] - 4s 79ms/step - loss: 0.7117 - accuracy: 0.7516 - val_loss: 0.8742 - val_accuracy: 0.6994\n",
            "Epoch 18/75\n",
            "49/49 [==============================] - 4s 80ms/step - loss: 0.6889 - accuracy: 0.7611 - val_loss: 0.7695 - val_accuracy: 0.7363\n",
            "Epoch 19/75\n",
            "49/49 [==============================] - 4s 92ms/step - loss: 0.6673 - accuracy: 0.7654 - val_loss: 0.7148 - val_accuracy: 0.7505\n",
            "Epoch 20/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.6458 - accuracy: 0.7742 - val_loss: 0.8622 - val_accuracy: 0.7143\n",
            "Epoch 21/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.6253 - accuracy: 0.7814 - val_loss: 0.7661 - val_accuracy: 0.7391\n",
            "Epoch 22/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.6052 - accuracy: 0.7873 - val_loss: 0.8442 - val_accuracy: 0.7219\n",
            "Epoch 23/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.5937 - accuracy: 0.7942 - val_loss: 0.8437 - val_accuracy: 0.7240\n",
            "Epoch 24/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.5775 - accuracy: 0.7995 - val_loss: 0.8974 - val_accuracy: 0.7112\n",
            "Epoch 25/75\n",
            "49/49 [==============================] - 4s 79ms/step - loss: 0.5626 - accuracy: 0.8049 - val_loss: 0.6632 - val_accuracy: 0.7795\n",
            "Epoch 26/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.5503 - accuracy: 0.8095 - val_loss: 0.7426 - val_accuracy: 0.7676\n",
            "Epoch 27/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.5332 - accuracy: 0.8157 - val_loss: 0.7494 - val_accuracy: 0.7580\n",
            "Epoch 28/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.5214 - accuracy: 0.8176 - val_loss: 0.7852 - val_accuracy: 0.7514\n",
            "Epoch 29/75\n",
            "49/49 [==============================] - 4s 80ms/step - loss: 0.5099 - accuracy: 0.8217 - val_loss: 0.5777 - val_accuracy: 0.8050\n",
            "Epoch 30/75\n",
            "49/49 [==============================] - 3s 68ms/step - loss: 0.4967 - accuracy: 0.8275 - val_loss: 0.8676 - val_accuracy: 0.7350\n",
            "Epoch 31/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.4853 - accuracy: 0.8302 - val_loss: 0.6519 - val_accuracy: 0.7918\n",
            "Epoch 32/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.4759 - accuracy: 0.8338 - val_loss: 0.7678 - val_accuracy: 0.7612\n",
            "Epoch 33/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.4645 - accuracy: 0.8380 - val_loss: 0.5920 - val_accuracy: 0.8094\n",
            "Epoch 34/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.4551 - accuracy: 0.8398 - val_loss: 0.5999 - val_accuracy: 0.8006\n",
            "Epoch 35/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.4456 - accuracy: 0.8446 - val_loss: 0.6677 - val_accuracy: 0.7866\n",
            "Epoch 36/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.4391 - accuracy: 0.8481 - val_loss: 0.6607 - val_accuracy: 0.7894\n",
            "Epoch 37/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.4325 - accuracy: 0.8491 - val_loss: 0.6403 - val_accuracy: 0.7988\n",
            "Epoch 38/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.4198 - accuracy: 0.8539 - val_loss: 0.6342 - val_accuracy: 0.7992\n",
            "Epoch 39/75\n",
            "49/49 [==============================] - 4s 80ms/step - loss: 0.4143 - accuracy: 0.8553 - val_loss: 0.5624 - val_accuracy: 0.8109\n",
            "Epoch 40/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.3992 - accuracy: 0.8621 - val_loss: 0.6973 - val_accuracy: 0.7850\n",
            "Epoch 41/75\n",
            "49/49 [==============================] - 3s 69ms/step - loss: 0.3957 - accuracy: 0.8624 - val_loss: 0.6147 - val_accuracy: 0.8032\n",
            "Epoch 42/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.3826 - accuracy: 0.8664 - val_loss: 0.6888 - val_accuracy: 0.7835\n",
            "Epoch 43/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.3800 - accuracy: 0.8691 - val_loss: 0.6176 - val_accuracy: 0.8085\n",
            "Epoch 44/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.3723 - accuracy: 0.8706 - val_loss: 0.5988 - val_accuracy: 0.8095\n",
            "Epoch 45/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.3569 - accuracy: 0.8762 - val_loss: 0.6429 - val_accuracy: 0.8056\n",
            "Epoch 46/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.3567 - accuracy: 0.8744 - val_loss: 0.6850 - val_accuracy: 0.7954\n",
            "Epoch 47/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.3501 - accuracy: 0.8772 - val_loss: 0.7214 - val_accuracy: 0.7867\n",
            "Epoch 48/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.3438 - accuracy: 0.8810 - val_loss: 0.6332 - val_accuracy: 0.8129\n",
            "Epoch 49/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.3396 - accuracy: 0.8801 - val_loss: 0.5992 - val_accuracy: 0.8138\n",
            "Epoch 50/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.3351 - accuracy: 0.8826 - val_loss: 0.6417 - val_accuracy: 0.8100\n",
            "Epoch 51/75\n",
            "49/49 [==============================] - 4s 89ms/step - loss: 0.3291 - accuracy: 0.8869 - val_loss: 0.5593 - val_accuracy: 0.8310\n",
            "Epoch 52/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.3192 - accuracy: 0.8890 - val_loss: 0.6123 - val_accuracy: 0.8143\n",
            "Epoch 53/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.3173 - accuracy: 0.8884 - val_loss: 0.6002 - val_accuracy: 0.8196\n",
            "Epoch 54/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.3118 - accuracy: 0.8915 - val_loss: 0.6346 - val_accuracy: 0.8064\n",
            "Epoch 55/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.3062 - accuracy: 0.8923 - val_loss: 0.5771 - val_accuracy: 0.8233\n",
            "Epoch 56/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.2980 - accuracy: 0.8953 - val_loss: 0.5821 - val_accuracy: 0.8227\n",
            "Epoch 57/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.3002 - accuracy: 0.8939 - val_loss: 0.6483 - val_accuracy: 0.8161\n",
            "Epoch 58/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.2868 - accuracy: 0.9000 - val_loss: 0.5807 - val_accuracy: 0.8229\n",
            "Epoch 59/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.2819 - accuracy: 0.9016 - val_loss: 0.6128 - val_accuracy: 0.8228\n",
            "Epoch 60/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.2835 - accuracy: 0.9017 - val_loss: 0.6303 - val_accuracy: 0.8144\n",
            "Epoch 61/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.2737 - accuracy: 0.9046 - val_loss: 0.5659 - val_accuracy: 0.8338\n",
            "Epoch 62/75\n",
            "49/49 [==============================] - 3s 67ms/step - loss: 0.2739 - accuracy: 0.9024 - val_loss: 0.8854 - val_accuracy: 0.7725\n",
            "Epoch 63/75\n",
            "49/49 [==============================] - 4s 80ms/step - loss: 0.2700 - accuracy: 0.9049 - val_loss: 0.5315 - val_accuracy: 0.8405\n",
            "Epoch 64/75\n",
            "49/49 [==============================] - 3s 59ms/step - loss: 0.2621 - accuracy: 0.9079 - val_loss: 0.5786 - val_accuracy: 0.8336\n",
            "Epoch 65/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.2605 - accuracy: 0.9093 - val_loss: 0.6567 - val_accuracy: 0.8174\n",
            "Epoch 66/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.2522 - accuracy: 0.9104 - val_loss: 0.5887 - val_accuracy: 0.8335\n",
            "Epoch 67/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.2546 - accuracy: 0.9124 - val_loss: 0.6528 - val_accuracy: 0.8185\n",
            "Epoch 68/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.2534 - accuracy: 0.9108 - val_loss: 0.6235 - val_accuracy: 0.8323\n",
            "Epoch 69/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.2473 - accuracy: 0.9137 - val_loss: 0.6869 - val_accuracy: 0.8120\n",
            "Epoch 70/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.2393 - accuracy: 0.9160 - val_loss: 0.6747 - val_accuracy: 0.8181\n",
            "Epoch 71/75\n",
            "49/49 [==============================] - 3s 58ms/step - loss: 0.2365 - accuracy: 0.9162 - val_loss: 0.5717 - val_accuracy: 0.8423\n",
            "Epoch 72/75\n",
            "49/49 [==============================] - 3s 56ms/step - loss: 0.2361 - accuracy: 0.9166 - val_loss: 0.6208 - val_accuracy: 0.8299\n",
            "Epoch 73/75\n",
            "49/49 [==============================] - 3s 67ms/step - loss: 0.2277 - accuracy: 0.9221 - val_loss: 0.6681 - val_accuracy: 0.8129\n",
            "Epoch 74/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.2279 - accuracy: 0.9214 - val_loss: 0.6471 - val_accuracy: 0.8314\n",
            "Epoch 75/75\n",
            "49/49 [==============================] - 3s 57ms/step - loss: 0.2256 - accuracy: 0.9209 - val_loss: 0.8144 - val_accuracy: 0.7938\n",
            "Network takes 297.861 seconds to train\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}